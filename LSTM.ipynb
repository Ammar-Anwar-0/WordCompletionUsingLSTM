{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89d47c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4abf2b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset to inspect the contents\n",
    "shakespeare = pd.read_csv(\"Shakespeare_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bf0270b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataline</th>\n",
       "      <th>Play</th>\n",
       "      <th>PlayerLinenumber</th>\n",
       "      <th>ActSceneLine</th>\n",
       "      <th>Player</th>\n",
       "      <th>PlayerLine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Henry IV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ACT I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Henry IV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SCENE I. London. The palace.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Henry IV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Enter KING HENRY, LORD JOHN OF LANCASTER, the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Henry IV</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.1.1</td>\n",
       "      <td>KING HENRY IV</td>\n",
       "      <td>So shaken as we are, so wan with care,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Henry IV</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.1.2</td>\n",
       "      <td>KING HENRY IV</td>\n",
       "      <td>Find we a time for frighted peace to pant,</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Dataline      Play  PlayerLinenumber ActSceneLine         Player  \\\n",
       "0         1  Henry IV               NaN          NaN            NaN   \n",
       "1         2  Henry IV               NaN          NaN            NaN   \n",
       "2         3  Henry IV               NaN          NaN            NaN   \n",
       "3         4  Henry IV               1.0        1.1.1  KING HENRY IV   \n",
       "4         5  Henry IV               1.0        1.1.2  KING HENRY IV   \n",
       "\n",
       "                                          PlayerLine  \n",
       "0                                              ACT I  \n",
       "1                       SCENE I. London. The palace.  \n",
       "2  Enter KING HENRY, LORD JOHN OF LANCASTER, the ...  \n",
       "3             So shaken as we are, so wan with care,  \n",
       "4         Find we a time for frighted peace to pant,  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first few rows of the dataset\n",
    "shakespeare.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39e357b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13339844",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56674b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c1402ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                [act]\n",
       "1                              [scene, london, palace]\n",
       "2    [enter, king, henry, lord, john, lancaster, ea...\n",
       "3                                  [shaken, wan, care]\n",
       "4                  [find, time, frighted, peace, pant]\n",
       "Name: PlayerLine, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter dataset to only include rows where PlayerLine is not NaN\n",
    "spoken_lines = shakespeare['PlayerLine'].dropna()\n",
    "\n",
    "# Convert all lines to lowercase\n",
    "spoken_lines = spoken_lines.str.lower()\n",
    "\n",
    "# Remove stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "tokenized_lines = spoken_lines.apply(lambda line: [word for word in word_tokenize(line) if word.isalpha() and word not in stop_words])\n",
    "\n",
    "# Display a sample of tokenized lines\n",
    "tokenized_lines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542cbd14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f98f3f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "523cb2de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0                                                [211]\n",
       " 1                                       [55, 679, 448]\n",
       " 2    [12, 20, 193, 6, 273, 1021, 736, 2155, 7, 2716...\n",
       " 3                                    [9004, 9005, 318]\n",
       " 4                           [106, 38, 3719, 107, 9006]\n",
       " Name: PlayerLine, dtype: object,\n",
       " {'thou': 1,\n",
       "  'thy': 2,\n",
       "  'shall': 3,\n",
       "  'thee': 4,\n",
       "  'good': 5,\n",
       "  'lord': 6,\n",
       "  'sir': 7,\n",
       "  'come': 8,\n",
       "  'let': 9,\n",
       "  'would': 10})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Flatten all tokenized lines into a single list of words\n",
    "all_words = [word for line in tokenized_lines for word in line]\n",
    "\n",
    "# Create a vocabulary by counting the frequency of each word\n",
    "word_counts = Counter(all_words)\n",
    "vocabulary = {word: i+1 for i, (word, _) in enumerate(word_counts.most_common())}\n",
    "\n",
    "# Convert the tokenized lines into sequences of integers\n",
    "sequences = tokenized_lines.apply(lambda line: [vocabulary[word] for word in line])\n",
    "\n",
    "# Display a sample of the vocabulary and sequences\n",
    "vocabulary_sample = dict(list(vocabulary.items())[:10])  # Show first 10 entries of the vocabulary\n",
    "sequences.head(), vocabulary_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1176eea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1acfda90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tensorflow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac04797d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  12   20  193    6  273]\n",
      " [  20  193    6  273 1021]\n",
      " [ 193    6  273 1021  736]\n",
      " [   6  273 1021  736 2155]\n",
      " [ 273 1021  736 2155    7]] [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Define the sequence length\n",
    "sequence_length = 5\n",
    "\n",
    "# Prepare the input sequences and their corresponding targets\n",
    "input_sequences = []\n",
    "targets = []\n",
    "\n",
    "for seq in sequences:\n",
    "    for i in range(sequence_length, len(seq)):\n",
    "        # Extract sequences of the given length\n",
    "        input_sequences.append(seq[i-sequence_length:i])\n",
    "        # Target is the next word in the sequence\n",
    "        targets.append(seq[i])\n",
    "\n",
    "# Convert the lists to numpy arrays\n",
    "input_sequences = np.array(input_sequences)\n",
    "targets = np.array(targets)\n",
    "\n",
    "# Pad the input sequences so all are of the same length\n",
    "input_sequences = pad_sequences(input_sequences, maxlen=sequence_length, padding='pre')\n",
    "\n",
    "# One-hot encode the target words\n",
    "vocab_size = len(vocabulary) + 1  # Add 1 for padding\n",
    "targets = to_categorical(targets, num_classes=vocab_size)\n",
    "\n",
    "# Display a sample of the input sequences and targets\n",
    "print(input_sequences[:5], targets[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af25c735",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7474db99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Assuming 'vocabulary' is a dictionary mapping words to indices\n",
    "# Save the vocabulary to a file\n",
    "with open('vocabulary.pkl', 'wb') as f:\n",
    "    pickle.dump(vocabulary, f)\n",
    "\n",
    "# If you have other data structures like reverse vocabulary or list of words, save them similarly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ac43cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define model architecture\n",
    "model = Sequential()\n",
    "\n",
    "# Embedding layer to convert word indexes into dense embeddings\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=200, input_length=sequence_length))\n",
    "\n",
    "# LSTM layer to learn sequential patterns\n",
    "model.add(LSTM(units=300))\n",
    "\n",
    "# Output layer with softmax activation to predict the next word\n",
    "model.add(Dense(units=vocab_size, activation='softmax'))\n",
    "\n",
    "# Compile the model with categorical crossentropy loss and Adam optimizer\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Display model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5409787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 117ms/step - accuracy: 0.0135 - loss: 9.4728 - val_accuracy: 0.0241 - val_loss: 8.4780\n",
      "Epoch 2/80\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 112ms/step - accuracy: 0.0183 - loss: 7.5586 - val_accuracy: 0.0244 - val_loss: 8.6393\n",
      "Epoch 3/80\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 114ms/step - accuracy: 0.0146 - loss: 7.3605 - val_accuracy: 0.0241 - val_loss: 8.7691\n",
      "Epoch 4/80\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 113ms/step - accuracy: 0.0137 - loss: 7.2635 - val_accuracy: 0.0244 - val_loss: 8.9083\n",
      "Epoch 5/80\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 114ms/step - accuracy: 0.0126 - loss: 7.2112 - val_accuracy: 0.0230 - val_loss: 9.2495\n",
      "Epoch 6/80\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 117ms/step - accuracy: 0.0201 - loss: 7.0484 - val_accuracy: 0.0223 - val_loss: 9.2970\n",
      "Epoch 7/80\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 116ms/step - accuracy: 0.0237 - loss: 6.8323 - val_accuracy: 0.0291 - val_loss: 9.6887\n",
      "Epoch 8/80\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 120ms/step - accuracy: 0.0273 - loss: 6.5668 - val_accuracy: 0.0320 - val_loss: 9.8598\n",
      "Epoch 9/80\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 118ms/step - accuracy: 0.0372 - loss: 6.2942 - val_accuracy: 0.0234 - val_loss: 10.4081\n",
      "Epoch 10/80\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 117ms/step - accuracy: 0.0427 - loss: 6.0025 - val_accuracy: 0.0230 - val_loss: 10.2468\n",
      "Epoch 11/80\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 122ms/step - accuracy: 0.0543 - loss: 5.7136 - val_accuracy: 0.0201 - val_loss: 10.7204\n",
      "Epoch 12/80\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 124ms/step - accuracy: 0.0742 - loss: 5.3753 - val_accuracy: 0.0201 - val_loss: 11.0994\n",
      "Epoch 13/80\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 120ms/step - accuracy: 0.0957 - loss: 5.0395 - val_accuracy: 0.0183 - val_loss: 11.3682\n",
      "Epoch 14/80\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 121ms/step - accuracy: 0.1265 - loss: 4.6982 - val_accuracy: 0.0183 - val_loss: 11.5940\n",
      "Epoch 15/80\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 121ms/step - accuracy: 0.1699 - loss: 4.4047 - val_accuracy: 0.0173 - val_loss: 11.8954\n",
      "Epoch 16/80\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 126ms/step - accuracy: 0.2202 - loss: 4.0491 - val_accuracy: 0.0176 - val_loss: 12.0494\n",
      "Epoch 17/80\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 123ms/step - accuracy: 0.2802 - loss: 3.7475 - val_accuracy: 0.0144 - val_loss: 12.3288\n",
      "Epoch 18/80\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 126ms/step - accuracy: 0.3475 - loss: 3.4505 - val_accuracy: 0.0122 - val_loss: 12.5174\n",
      "Epoch 19/80\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 125ms/step - accuracy: 0.4245 - loss: 3.1355 - val_accuracy: 0.0111 - val_loss: 12.6959\n",
      "Epoch 20/80\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 127ms/step - accuracy: 0.4652 - loss: 2.8812 - val_accuracy: 0.0129 - val_loss: 12.8589\n",
      "Epoch 21/80\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 121ms/step - accuracy: 0.5379 - loss: 2.5621 - val_accuracy: 0.0119 - val_loss: 13.0924\n",
      "Epoch 22/80\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 133ms/step - accuracy: 0.5890 - loss: 2.3161 - val_accuracy: 0.0122 - val_loss: 13.2166\n",
      "Epoch 23/80\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 130ms/step - accuracy: 0.6377 - loss: 2.0777 - val_accuracy: 0.0104 - val_loss: 13.4016\n",
      "Epoch 24/80\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 119ms/step - accuracy: 0.6636 - loss: 1.9066 - val_accuracy: 0.0119 - val_loss: 13.5694\n",
      "Epoch 25/80\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 122ms/step - accuracy: 0.7135 - loss: 1.6820 - val_accuracy: 0.0122 - val_loss: 13.7126\n",
      "Epoch 26/80\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 124ms/step - accuracy: 0.7455 - loss: 1.5069 - val_accuracy: 0.0104 - val_loss: 13.8347\n",
      "Epoch 27/80\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 123ms/step - accuracy: 0.7769 - loss: 1.3480 - val_accuracy: 0.0122 - val_loss: 13.8985\n",
      "Epoch 28/80\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 119ms/step - accuracy: 0.8050 - loss: 1.1998 - val_accuracy: 0.0104 - val_loss: 14.0717\n",
      "Epoch 29/80\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 123ms/step - accuracy: 0.8365 - loss: 1.0578 - val_accuracy: 0.0122 - val_loss: 14.1771\n",
      "Epoch 30/80\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 122ms/step - accuracy: 0.8518 - loss: 0.9502 - val_accuracy: 0.0104 - val_loss: 14.3121\n",
      "Epoch 31/80\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 123ms/step - accuracy: 0.8792 - loss: 0.8257 - val_accuracy: 0.0104 - val_loss: 14.4469\n",
      "Epoch 32/80\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 123ms/step - accuracy: 0.8983 - loss: 0.7374 - val_accuracy: 0.0104 - val_loss: 14.4747\n",
      "Epoch 33/80\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 120ms/step - accuracy: 0.9149 - loss: 0.6517 - val_accuracy: 0.0119 - val_loss: 14.6089\n",
      "Epoch 34/80\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 123ms/step - accuracy: 0.9308 - loss: 0.5729 - val_accuracy: 0.0093 - val_loss: 14.6634\n",
      "Epoch 35/80\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 121ms/step - accuracy: 0.9435 - loss: 0.4981 - val_accuracy: 0.0108 - val_loss: 14.7997\n",
      "Epoch 36/80\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 122ms/step - accuracy: 0.9537 - loss: 0.4475 - val_accuracy: 0.0108 - val_loss: 14.8767\n",
      "Epoch 37/80\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 167ms/step - accuracy: 0.9615 - loss: 0.3963 - val_accuracy: 0.0104 - val_loss: 14.9473\n",
      "Epoch 38/80\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 133ms/step - accuracy: 0.9692 - loss: 0.3449 - val_accuracy: 0.0111 - val_loss: 14.9773\n",
      "Epoch 39/80\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 129ms/step - accuracy: 0.9749 - loss: 0.3052 - val_accuracy: 0.0101 - val_loss: 15.0900\n",
      "Epoch 40/80\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 145ms/step - accuracy: 0.9809 - loss: 0.2627 - val_accuracy: 0.0108 - val_loss: 15.1054\n",
      "Epoch 41/80\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 130ms/step - accuracy: 0.9834 - loss: 0.2356 - val_accuracy: 0.0104 - val_loss: 15.2041\n",
      "Epoch 42/80\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 127ms/step - accuracy: 0.9875 - loss: 0.2040 - val_accuracy: 0.0108 - val_loss: 15.2436\n",
      "Epoch 43/80\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 129ms/step - accuracy: 0.9860 - loss: 0.1899 - val_accuracy: 0.0097 - val_loss: 15.3361\n",
      "Epoch 44/80\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 124ms/step - accuracy: 0.9917 - loss: 0.1619 - val_accuracy: 0.0101 - val_loss: 15.3771\n",
      "Epoch 45/80\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 127ms/step - accuracy: 0.9896 - loss: 0.1486 - val_accuracy: 0.0111 - val_loss: 15.4342\n",
      "Epoch 46/80\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 144ms/step - accuracy: 0.9916 - loss: 0.1300 - val_accuracy: 0.0093 - val_loss: 15.4875\n",
      "Epoch 47/80\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 129ms/step - accuracy: 0.9916 - loss: 0.1220 - val_accuracy: 0.0097 - val_loss: 15.5100\n",
      "Epoch 48/80\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 126ms/step - accuracy: 0.9935 - loss: 0.1038 - val_accuracy: 0.0101 - val_loss: 15.5753\n",
      "Epoch 49/80\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 124ms/step - accuracy: 0.9927 - loss: 0.0976 - val_accuracy: 0.0090 - val_loss: 15.6224\n",
      "Epoch 50/80\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 130ms/step - accuracy: 0.9942 - loss: 0.0872 - val_accuracy: 0.0104 - val_loss: 15.6759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/80\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 143ms/step - accuracy: 0.9948 - loss: 0.0789 - val_accuracy: 0.0101 - val_loss: 15.7312\n",
      "Epoch 52/80\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 144ms/step - accuracy: 0.9926 - loss: 0.0773 - val_accuracy: 0.0097 - val_loss: 15.7597\n",
      "Epoch 53/80\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 143ms/step - accuracy: 0.9929 - loss: 0.0706 - val_accuracy: 0.0090 - val_loss: 15.8001\n",
      "Epoch 54/80\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 143ms/step - accuracy: 0.9932 - loss: 0.0670 - val_accuracy: 0.0083 - val_loss: 15.8499\n",
      "Epoch 55/80\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 150ms/step - accuracy: 0.9926 - loss: 0.0592 - val_accuracy: 0.0090 - val_loss: 15.8876\n",
      "Epoch 56/80\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 143ms/step - accuracy: 0.9946 - loss: 0.0542 - val_accuracy: 0.0086 - val_loss: 15.9078\n",
      "Epoch 57/80\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 174ms/step - accuracy: 0.9926 - loss: 0.0540 - val_accuracy: 0.0090 - val_loss: 15.9468\n",
      "Epoch 58/80\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 145ms/step - accuracy: 0.9930 - loss: 0.0494 - val_accuracy: 0.0093 - val_loss: 15.9742\n",
      "Epoch 59/80\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 144ms/step - accuracy: 0.9946 - loss: 0.0448 - val_accuracy: 0.0093 - val_loss: 16.0444\n",
      "Epoch 60/80\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 144ms/step - accuracy: 0.9931 - loss: 0.0447 - val_accuracy: 0.0086 - val_loss: 16.0604\n",
      "Epoch 61/80\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 140ms/step - accuracy: 0.9936 - loss: 0.0428 - val_accuracy: 0.0090 - val_loss: 16.0876\n",
      "Epoch 62/80\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 133ms/step - accuracy: 0.9931 - loss: 0.0429 - val_accuracy: 0.0086 - val_loss: 16.1275\n",
      "Epoch 63/80\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 131ms/step - accuracy: 0.9944 - loss: 0.0394 - val_accuracy: 0.0086 - val_loss: 16.1688\n",
      "Epoch 64/80\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 129ms/step - accuracy: 0.9933 - loss: 0.0374 - val_accuracy: 0.0086 - val_loss: 16.2221\n",
      "Epoch 65/80\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 149ms/step - accuracy: 0.9945 - loss: 0.0344 - val_accuracy: 0.0083 - val_loss: 16.2379\n",
      "Epoch 66/80\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 129ms/step - accuracy: 0.9937 - loss: 0.0336 - val_accuracy: 0.0086 - val_loss: 16.2525\n",
      "Epoch 67/80\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 126ms/step - accuracy: 0.9946 - loss: 0.0304 - val_accuracy: 0.0093 - val_loss: 16.2946\n",
      "Epoch 68/80\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 132ms/step - accuracy: 0.9928 - loss: 0.0324 - val_accuracy: 0.0090 - val_loss: 16.3237\n",
      "Epoch 69/80\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 124ms/step - accuracy: 0.9937 - loss: 0.0298 - val_accuracy: 0.0086 - val_loss: 16.3651\n",
      "Epoch 70/80\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 123ms/step - accuracy: 0.9953 - loss: 0.0259 - val_accuracy: 0.0090 - val_loss: 16.4033\n",
      "Epoch 71/80\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 139ms/step - accuracy: 0.9920 - loss: 0.0300 - val_accuracy: 0.0090 - val_loss: 16.4234\n",
      "Epoch 72/80\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 131ms/step - accuracy: 0.9927 - loss: 0.0290 - val_accuracy: 0.0090 - val_loss: 16.4576\n",
      "Epoch 73/80\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 126ms/step - accuracy: 0.9946 - loss: 0.0253 - val_accuracy: 0.0083 - val_loss: 16.4620\n",
      "Epoch 74/80\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 132ms/step - accuracy: 0.9932 - loss: 0.0255 - val_accuracy: 0.0086 - val_loss: 16.5058\n",
      "Epoch 75/80\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 130ms/step - accuracy: 0.9958 - loss: 0.0231 - val_accuracy: 0.0090 - val_loss: 16.5045\n",
      "Epoch 76/80\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 141ms/step - accuracy: 0.9935 - loss: 0.0245 - val_accuracy: 0.0083 - val_loss: 16.5580\n",
      "Epoch 77/80\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 128ms/step - accuracy: 0.9949 - loss: 0.0220 - val_accuracy: 0.0086 - val_loss: 16.6087\n",
      "Epoch 78/80\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 140ms/step - accuracy: 0.9929 - loss: 0.0237 - val_accuracy: 0.0083 - val_loss: 16.6092\n",
      "Epoch 79/80\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 132ms/step - accuracy: 0.9942 - loss: 0.0205 - val_accuracy: 0.0083 - val_loss: 16.6533\n",
      "Epoch 80/80\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 138ms/step - accuracy: 0.9939 - loss: 0.0212 - val_accuracy: 0.0083 - val_loss: 16.6712\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(input_sequences, targets, epochs=80, batch_size=128, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ca2ae45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Save the model to a file\n",
    "model.save(\"shakespeare_lstm_model3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a646629",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2578594b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step\n",
      "Input text: Poins!\n",
      "Predicted next word: sin\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Load the pre-trained model\n",
    "model = tf.keras.models.load_model(\"shakespeare_lstm_model3.h5\")\n",
    "\n",
    "# Function to convert a sequence of words to indices using vocabulary\n",
    "def text_to_sequence(text, vocabulary):\n",
    "    words = text.lower().split()  # Tokenize and lowercase input text\n",
    "    # Use 0 as a fallback value if a word is not in the vocabulary\n",
    "    sequence = [vocabulary.get(word, 0) for word in words]  # Convert words to indices, use 0 for unknown words\n",
    "    return sequence\n",
    "\n",
    "# Function to convert index to a word using the reverse vocabulary\n",
    "def index_to_word(index, vocabulary):\n",
    "    reverse_vocab = {i: word for word, i in vocabulary.items()}  # Reverse the vocabulary\n",
    "    return reverse_vocab.get(index, '<unk>')  # Get word from index, return '<unk>' if not found\n",
    "\n",
    "# Function to predict the next word given a sequence of text\n",
    "def predict_next_word(model, input_text, vocabulary, sequence_length):\n",
    "    # Convert the input text to a sequence of indices\n",
    "    sequence = text_to_sequence(input_text, vocabulary)\n",
    "    \n",
    "    # Ensure the sequence is of the correct length (padding/truncating if necessary)\n",
    "    if len(sequence) < sequence_length:\n",
    "        sequence = [0] * (sequence_length - len(sequence)) + sequence  # Pad with 0s (assuming 0 is padding index)\n",
    "    else:\n",
    "        sequence = sequence[-sequence_length:]  # Truncate to the correct sequence length\n",
    "    \n",
    "    # Reshape sequence for prediction (batch size of 1)\n",
    "    input_sequence = pad_sequences([sequence], maxlen=sequence_length, padding='pre')\n",
    "    \n",
    "    # Get the model's prediction (output probabilities for the next word)\n",
    "    predicted_probs = model.predict(input_sequence)\n",
    "    \n",
    "    # Get the index of the predicted word (the one with the highest probability)\n",
    "    predicted_index = np.argmax(predicted_probs, axis=-1)[0]\n",
    "    \n",
    "    # Convert the predicted index back to a word\n",
    "    predicted_word = index_to_word(predicted_index, vocabulary)\n",
    "    \n",
    "    return predicted_word\n",
    "\n",
    "# Example:\n",
    "input_text = \"Poins!\"\n",
    "predicted_word = predict_next_word(model, input_text, vocabulary, sequence_length=1)\n",
    "print(f\"Input text: {input_text}\")\n",
    "print(f\"Predicted next word: {predicted_word}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0e3c6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b63ecdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c3e9191a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(vocabulary.items(), columns=['word', 'index']).to_csv(\"vocabulary.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a4751a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from flask import Flask, request, jsonify\n",
    "# from flask_ngrok import run_with_ngrok\n",
    "# from tensorflow.keras.models import load_model\n",
    "\n",
    "#%pip install Flask flask-ngrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c11caa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the model\n",
    "# model = load_model(\"shakespeare_lstm_model.h5\")\n",
    "\n",
    "# # Load your vocabulary\n",
    "# vocabulary = pd.read_csv(\"vocabulary.csv\", index_col=0).to_dict()['index']  # Adjust according to how you saved it\n",
    "\n",
    "# # Create Flask app\n",
    "# app = Flask(__name__)\n",
    "# run_with_ngrok(app)  # Start ngrok when app is run\n",
    "\n",
    "# # Define a function to preprocess input text\n",
    "# def preprocess_input(text):\n",
    "#     # Tokenize and filter words\n",
    "#     stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "#     tokenized_line = [word for word in word_tokenize(text.lower()) if word.isalpha() and word not in stop_words]\n",
    "#     # Convert words to indexes\n",
    "#     sequence = [vocabulary[word] for word in tokenized_line if word in vocabulary]\n",
    "#     return sequence\n",
    "\n",
    "# @app.route('/predict', methods=['POST'])\n",
    "# def predict():\n",
    "#     # Get the partial sentence from the request\n",
    "#     data = request.json\n",
    "#     partial_sentence = data['sentence']\n",
    "    \n",
    "#     # Preprocess the input\n",
    "#     input_sequence = preprocess_input(partial_sentence)\n",
    "#     input_sequence = input_sequence[-5:]  # Get the last 5 words\n",
    "#     input_sequence = pad_sequences([input_sequence], maxlen=5, padding='pre')  # Pad if necessary\n",
    "\n",
    "#     # Make prediction\n",
    "#     predicted_probs = model.predict(input_sequence)\n",
    "#     predicted_word_index = np.argmax(predicted_probs, axis=-1)[0]\n",
    "    \n",
    "#     # Reverse the index to get the word\n",
    "#     predicted_word = [word for word, index in vocabulary.items() if index == predicted_word_index][0]\n",
    "\n",
    "#     return jsonify({'next_word': predicted_word})\n",
    "\n",
    "# # Start the Flask app (do not specify port here)\n",
    "# app.run()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "24d2ccb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run on BASH?\n",
    "\n",
    "#curl -X POST <http://127.0.0.1:5000>/predict -H \"Content-Type: application/json\" -d '{\"sentence\": \"To be or not to\"}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0837f2f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cedfc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1ab24cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "#from scikeras.wrappers import KerasClassifier\n",
    "#from sklearn.model_selection import GridSearchCV\n",
    "#from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Function to build the model\n",
    "# def build_model(lstm_units=100, embedding_dim=100, learning_rate=0.001):\n",
    "#     model = Sequential()\n",
    "#     model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=sequence_length))\n",
    "#     model.add(LSTM(units=lstm_units))\n",
    "#     model.add(Dense(units=vocab_size, activation='softmax'))\n",
    "    \n",
    "#     optimizer = Adam(learning_rate=learning_rate)\n",
    "#     model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b63c5dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = KerasClassifier(build_fn=build_model, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79d5fe06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Hyperparameters to tune\n",
    "# param_grid = {\n",
    "#     'lstm_units': [50, 100, 150],            # Number of LSTM units\n",
    "#     'embedding_dim': [50, 100],              # Embedding output dimensions\n",
    "#     'batch_size': [64, 128],                 # Batch size during training\n",
    "#     'epochs': [10, 20],                      # Number of epochs\n",
    "#     'learning_rate': [0.001, 0.0001]         # Learning rates\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "febf5e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearch with 3-fold cross-validation\n",
    "# grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, verbose=1)\n",
    "\n",
    "# Perform the grid search on the training data\n",
    "# grid_result = grid.fit(input_sequences, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00558bae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
